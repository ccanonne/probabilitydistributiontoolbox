\documentclass[10pt]{article}
\def\withcolors{1}
\def\withnotes{1}
\def\withindex{0}
\input{packages}
\input{preamble}

\newcommand{\dst}{\eps}
\newcommand{\ab}{k}
\newcommand{\ns}{n}
\newcommand{\errproba}{\delta}
\newcommand{\p}{\mathbf{p}}
\newcommand{\q}{\mathbf{q}}
\newcommand{\priv}{\varepsilon}
\newcommand{\privdelta}{\delta}
\renewcommand{\uniform}{\mathbf{u}}

\usepackage{filecontents}

\title{Uniformity testing of discrete distributions}
\date{July, 2020}
\author{Cl\'ement L. Canonne}

\usepackage{utopia}

\begin{document}
\maketitle

\begin{abstract}
The goal of this short note is to provide a short overview of the known algorithms to perform \emph{uniformity testing} of discrete distributions over a known domain of size $\ab$.
\end{abstract}

The main focus of this document is the question of \emph{uniformity testing} of probability distributions over a known discrete domain of size $\ab$\footnote{Without loss of generality, the set $[\ab]=\{1,2,\dots,\ab\}$}; that is, the question of deciding, based on observing a sequence of i.i.d.\ observations from some unknown probability distribution over domain $[\ab]$, whether this distribution is \emph{the} uniform distribution $\uniform_\ab$ over the domain~--~or, in the contrary, is statistically quite far from this model. Formally, it is defined as follows, where 
\[
    \totalvardist{\p}{\q} = \sup_{S\subseteq[\ab]}(\p(S)-\q(S)) = \frac{1}{2}\normone{\p-\q} \in[0,1]
\]
denotes the total variation distance between distributions:
\begin{definition}[Uniformity Testing]
  A \emph{uniformity testing algorithm with sample complexity $\ns$} takes as input a parameter $\dst \in(0,1]$ and $\ns$ i.i.d.\ samples from an unknown distribution $\p$ over $[\ab]$, and outputs either \accept or \reject. The algorithm must satisfy the following, where the probability is over the randomness of the samples:
  \begin{itemize}
    \item If $\p=\uniform_\ab$, then the algorithm outputs \accept with probability at least $2/3$;
    \item If $\totalvardist{\p}{\uniform_\ab}>\dst$, then the algorithm outputs \reject with probability at least $2/3$.
  \end{itemize}
The sample complexity of uniformity testing is then the minimum sample complexity over all uniformity testing algorithms.
\end{definition}
A couple remarks are in order: first, the above can be rephrased as a composite hypothesis testing (in a minimax setting), where $\mathcal{H}_0 = \{\uniform_\ab\}$ and $\mathcal{H}_1 = \setOfSuchThat{\p}{\totalvardist{\p}{\uniform_\ab} > \dst}$. Second, for simplicity, we focused in the above on a constant error probability (equal for both Type I and Type II), set to $1/3$. By standard arguments, one can in all settings considered here decrease this to an arbitrarily small $\errproba\in(0,1]$ at the price of a mere multiplicative $\log(1/\errproba)$ factor in the sample complexity,\footnote{Which is not optimal, as a $\sqrt{\log(1/\errproba)}$ is achievable instead~\cite{HuangM13,DiakonikolasGPP18}; but is good enough.} by repeating the test independently and taking the majority outcome.

It is known~\cite{Paninski08} that the sample complexity of uniformity testing with distance parameter $\dst\in(0,1]$ is $\Theta(\sqrt{\ab}/\dst^2)$. That's nice. Now, \emph{how do we perform uniformity testing, though?} 
There are several things to consider in a testing algorithm. For instance:
\begin{description}
  \item[Data efficiency:] does the algorithm achieve the optimal sample complexity $\Theta(\sqrt{\ab}/\dst^2)$?
  \item[Time efficiency:] how fast is the algorithm to run (as a function of $\ab,\dst$, and the number of samples $\ns$)?
  \item[Memory efficiency:] how much memory does the algorithm require (as a function of $\ab,\dst$, and $\ns$)?
  \item[Simplicity:] is the algorithm simple to describe and implement?
  \item[``Simplicity'':] is the algorithm simple to \emph{analyze}?
  \item[Robustness:] how \emph{tolerant} is the algorithm to breaches of the promise? I.e., does it accept distributions which are not \emph{exactly} uniform as well, or is it very brittle?
  \item[Elegance:] That's, like, your opinion, man.
  \item[Generalizable:] Does the algorithm have other features that might be desirable in other settings?
\end{description}

\noindent Let's make a table, just with a couple of those criteria.
\begin{table}[H]\centering
  \def\arraystretch{2.75}%  1 is the default, change whatever you need
% %   \begin{adjustwidth}{0in}{0in}% adjust the L and R margins by 1 inch
  \begin{tabular}{|c|c|c|c|}
  \hline
     & \bf Sample complexity & \bf Notes & \bf References \\\hline
    \bf Collision-based & $\dfrac{\ab^{1/2}}{\dst^2}$ & Tricky & \cite{GoldreichR00,DiakonikolasGPP19} \\\hline
    \bf Unique elements & $\dfrac{\ab^{1/2}}{\dst^2}$ & $\dst \gg 1/\ab^{1/4}$ & \cite{Paninski08} \\\hline
    \bf Modified $\chi^2$ & $\dfrac{\ab^{1/2}}{\dst^2}$ & Nope & \cite{ValiantV17,AcharyaDK15,DiakonikolasKN15} \\\hline
    \bf Empirical distance to uniform & $\dfrac{\ab^{1/2}}{\dst^2}$ & Biased & \cite{DiakonikolasGPP18} \\\hline
    \bf Random binary hashing & $\dfrac{\ab}{\dst^2}$ & Fun (+ fast, small space) & \cite{AcharyaCT19b} \\\hline
    \bf Bipartite collisions & $\dfrac{\ab^{1/2}}{\dst^2}$ & $\dst \gg 1/\ab^{1/10}$ & \cite{DiakonikolasGKR19} \\\hline
    \bf Empirical subset weighting & $\dfrac{\ab^{1/2}}{\dst^2}$ & $\dst \gg 1/\ab^{1/4}$ &  \\\hline
  \end{tabular}
% %   \end{adjustwidth}
  \caption{The current landscape of uniformity testing, based on the algorithms I know of. For ease of reading, we omit the $O(\cdot)$, $\Theta(\cdot)$, and $\Omega(\cdot)$'s from the table: all results should be read as asymptotic with regard to the parameters, up to absolute constants.}
\end{table}

A key insight, that underlies a lot of the algorithms above, is that here \emph{$\lp[2]$ distance is a good proxy for total variation distance}:
\begin{equation}
  \totalvardist{\p}{\uniform_k} = \frac{1}{2}\normone{\p-\uniform_\ab} \leq \frac{\sqrt{\ab}}{2}\normtwo{\p-\uniform_\ab}
\end{equation}
the inequality being Cauchy--Schwarz. So if $\totalvardist{\p}{\uniform_k}>\dst$, then $\normtwo{\p-\uniform_\ab}^2 > 4\dst^2/\ab$ (and, well, if $\totalvardist{\p}{\uniform_k}=0$ then $\normtwo{\p-\uniform_\ab}^2=0$ too, of course). Moreover, we have the very convenient fact, specific to the distance to uniform: for any distribution $\p$ over $[\ab]$,
\begin{equation}
  \normtwo{\p-\uniform_\ab}^2 = \sum_{i=1}^\ab (\p(i)-1/\ab)^2  = \sum_{i=1}^\ab \p(i)^2-1/\ab = \normtwo{\p}^2-1/\ab\,,
\end{equation}
so combining the two we get that $\totalvardist{\p}{\uniform_k}>\dst$ implies $\normtwo{\p}^2 > (1+4\dst^2)/\ab$.

\paragraph{Collision-based.} In view of the above, a very natural thing is to estimate $\normtwo{\p}^2$, in order to distinguish between $\normtwo{\p}^2 = 1/\ab$ (uniform) and $\normtwo{\p}^2 > (1+4\dst^2)/\ab$ ($\dst$-far from uniform). How to do that? Upon observing that the probability that two independent samples $x,y$ from $\p$ take the same value (a ``collision'') is exactly
\begin{equation}
    \probaDistrOf{x,y\sim\p}{x=y} = \sum_{i=1}^\ab \p(i)^2 = \normtwo{\p}^2
\end{equation}
an obvious idea is to take $\ns$ samples $x_1,\dots,x_\ns$, count the number of pairs that show a collision, and use that as an unbiased estimator $Z_1$ for $\normtwo{\p}^2$:
\begin{equation}
    Z_1 = \frac{1}{\binom{\ns}{2}} \sum_{s\neq t} \indic{x_s=x_t}\,.
\end{equation}
By the above, $\expect{Z_1} = \normtwo{\p}^2$. If we threshold $Z_1$ at say $(1+2\dst^2)/\ab$, we get a test. How big must $\ns$ be for this to work? We can use Chebyshev for that, we requires to bound $\var[Z]$. That's where things get tricky: to get the optimal bound $O(\sqrt{\ab}/\dst^2)$ instead of an (easier to obtain) $O(\sqrt{\ab}/\dst^4)$, the analysis of the variance has to be \emph{pretty} intricate. Doable, but unwieldy.

\paragraph{Unique elements.} Another idea? Count the number of elements that appear exactly \emph{once} among the $\ns$ samples taken. Why is that a good idea? The uniform distribution will have the fewer collisions, so, equivalently, will have the maximum number of unique elements. In this case, the estimator $Z_2$ (the number of unique elements) has expectation
\begin{equation}
  \expect{Z_2} = \ns \sum_{i=1}^\ab \p(i)(1-\p(i))^{\ns-1}
\end{equation}
which is\dots{} a thing? Note that under the uniform distribution $\uniform_\ab$, this is exactly $\ns (1-1/\ab)^{\ns-1}\approx \ns - \frac{\ns^2}{\ab}$, and under arbitrary $\p$ this is (making a bunch of approximations not always valid) $\approx \ns \sum_{i=1}^\ab \p(i)(1-\ns\p(i)) = \ns - \ns^2\normtwo{\p}^2$. So the gap in expectation between the two cases ``should'' be around $4\dst^2\ns^2/\ab$, and, if the variance goes well and the stars align (and they do), we will be able to use Chebyshev and argue that we can distinguish the two for $\ns=\Theta(\sqrt{\ab}/\dst^2)$.

Now, the annoying issue is that we count the number of \emph{distinct} elements, and it's quite unlikely there can ever be more than $\ab$ of them if the domain size is $\ab$. That explains, intuitively, the condition for the test to work: we need $\ns$ (the number of samples taken) to be smaller than $\ab$ (the maximum number of distinct elements one can ever hope to see), which gives, since we'll get $\ns = \Theta(\sqrt{\ab}/\dst^2)$, the condition $\dst \gg 1/\ab^{1/4}$. (A slight bummer.)

\paragraph{Modified $\chi^2$.} If you are a statistician, or just took Stats 101, or just got lost on Wikipedia at some point and randomly ended up on the wrong page, you may know of Pearson's $\chi^2$ test for goodness-of-fit: for every element $i$ of the domain, count how many times it appeared in the samples, $N_i$. Compute $\sum_{i} \frac{(N_i-\ns/\ab)^2}{\ns/\ab}$. Relax. 
To analyze that easily, it's helpful to think of taking $\poisson{\ns}$ samples instead of exactly $\ns$, as it greatly simplifies the analysis. Then the $N_i$'s become independent, with $N_i\sim\poisson{\ns\p(i)}$ (that not magic, it's Poissonization).

The bad news is that it does not actually lead to the optimal sample complexity: Poissonization introduces a bit more variance, and so the variance of this $\chi^2$ test can be too big due to the elements we only expect to see zero or once (so, most of them). The \emph{good} news is that a simple correction of that test, of the form
\begin{equation}
    Z_3 = \sum_{i=1}^\ab \frac{(N_i-\ns/\ab)^2- N_i}{\ns/\ab}
\end{equation}
\emph{does} have a much smaller variance, and a threshold test of the form ``$Z_3 > \tau$?'' leads to the right sample complexity. The expectation of $Z_3$ is then just 
\[
    \expect{Z_3} = \ns\ab \normtwo{\p-\uniform_k}^2
\]
which is perfect. Analyzing this test just boils down, again, to bounding the variance of $Z_3$ and invoking Chebyshev's inequality\dots{} It's a good exercise, and under the Poissonization assumption not that hard. (Try \emph{without} removing $N_i$ in the numerator, though, and see what you get\dots)

\paragraph{Empirical distance to uniform.} Let's take a break from $\lp[2]$ and consider another, very natural thing to consider: the \emph{plugin estimator}. Since we have $\ns$ samples from $\p$, we can compute the empirical estimator of the distribution, $\hat{\p}$. Now, we want to test whether $\totalvardist{\p}{\uniform_\ab}=0$ v. $\totalvardist{\p}{\uniform_\ab}>\dst$? Why not consider 
\begin{equation}
    Z_4 = \totalvardist{\hat{\p}}{\uniform_\ab}
\end{equation}
the empirical distance to uniform? A reason might be: \emph{this sounds like a terrible idea.} Unless $\ns = \Omega(\ab)$ (which is much more than what we want), the empirical distribution $\hat{\p}$ will be at distance $1-o(1)$ from uniform, \emph{even} if $\p$ is actually uniform. 

That's the thing, though: hell is in the $o(1)$ details. Sure, $\expect{Z_4}$ will be \emph{almost} $1$ whether $\p$ is uniform or far from it unless $\ns = \Omega(\ab)$. But this ``almost'' will be different in the two cases! Carefully analyzing this tiny gap in expectation, and showing that $Z_4$ concentrates well enough around its expectation to preserve this tiny gap, amazingly leads to a tester with optimal sample complexity $\ns = \Theta(\sqrt{\ab}/\dst^2)$.

\paragraph{Random binary hashing.} Now for a tester that is \emph{not} sample-optimal (but has other advantages, and is relatively cute). If there is one thing we know how to do optimally, it's estimating the bias of a coin. We don't have a coin (Bernoulli) here, we have a glorious $(\ab-1)$-dimensional object.
Hell, let's just randomly make it a coin, shall we? Pick your favourite ($4$-wise independent) hash function $h\colon[\ab]\to\{0,1\}$, thus randomly partitioning the domain $[\ab]$ in two sets $S_0,S_1$. Hash all the $\ns$ samples you got: \emph{now} we have a random coin!

Let's estimate its bias then: we know exactly what this should be under the uniform distribution: $\uniform_\ab(S_0)$. If only we could argue that $\p(S_0)$ noticeably differs from $\uniform_\ab(S_0)$ (with high probability over the random choice of the hash function) whenever $\p$ is $\dst$-far from uniform, we'd be good. Turns out\dots it is the case:
\begin{equation}
    \probaDistrOf{S\subseteq [\ab]}{ |\p(S)-\uniform_\ab(S)| = \Omega(\dst/\sqrt{\ab}) } = \Omega(1)
\end{equation}
So we can just do exactly this: we need to estimate the bias $\p(S_0)$ up to an additive $\alpha \asymp \dst/\sqrt{\ab}$. This can be done with $\ns = \Theta(1/\alpha^2)= \Theta(\ab/\dst^2)$ samples, as desired.

\paragraph{Bipartite collisions.} In the collision-based tester above, we took a multiset $S$ of $\ns$ samples from $\p$, and looked at the number of ``collisions'' in $S$ to define our statistic $Z_1$. That is fine, but requires to keep in memory all the samples observed so far. One related idea would be to instead take \emph{two} multisets $S_1,S_2$ of $\ns_1$ and $\ns_2$ samples, and only count ``bipartite collisions,'' i.e., collisions between a sample of $S_1$ and one of $S_2$:
\begin{equation}
    Z_5 = \frac{1}{\ns_1 \ns_2}\sum_{(x,y)\in S_1\times S_2} \indic{x=y}
\end{equation}
One can check that $\expect{Z_5} = \normtwo{\p}^2$. Back to $\lp[2]$ as proxy! Compared to the ``vanilla'' collision-based test, this is more flexible ($S_1,S_2$ need not be of the same size), and thus lends itself to some settings where a tradeoff between $\ns_1$ and $\ns_2$ is desirable (roughly speaking, one needs $\ns_1\ns_2 \gtrsim \ab/\dst^4$, and the sample complexity is $\ns=\ns_1+\ns_2$). For the case $\ns_1=\ns_2$, this retrieves the optimal $\ns \asymp \sqrt{\ab}/\dst^2$, with some extra technical condition stemming from the analysis, unfortunately: one needs $\dst = \Omega(1/\ab^{1/10})$.

\paragraph{Empirical subset weighting.} That one, I really like. It's adaptive, it's weird, and (I think) it's new. Fix a parameter $1\leq s \leq \ns$. Take $\ns$ samples from $\p$, and consider the set $S$ (not multiset) induced by the first $s$ samples you get. One can check that
\begin{equation}
    \expect{\p(S)} = \sum_{i=1}^\ab \p(i) (1-(1-\p(i))^s)
\end{equation}
which should be roughly (making a bunch of approximations) $\expect{\p(S)}\approx s\normtwo{\p}^2$. Under the uniform distribution, this is exactly $(1-(1-1/\ab)^s)\approx s/\ab$, where the approximation is valid for $s\ll \ab$.

Great: we have a new estimator for (roughly) the $\lp[2]$ norm! Now, assuming things went well, as the end of this first stage we have a set $S$ such that $\p(S)$ is approximately either $s/\ab$ or $s\normtwo{\p}^2\geq s(1+\Omega(\dst^2))/\ab$ (we just argued that this is what things happen \emph{in expectation}).\footnote{Some more details are required to argue that $\p(S)$ does concentrate enough around its expectation.} So, let's do a second stage! Take the next $\ns-s$ samples, and just count the number of them which fall in $S$: this is allows you to estimate $\p(S)$  up to an additive $s\dst^2/\ab$, as long as
\[
      \ns - s \gtrsim \frac{\ab}{s\dst^4}
\]
(exercise: check that). Optimizing, we get that for $s=\ns/2$ this leads to $\ns \asymp \sqrt{\ab}/\dst^2$: optimal sample complexity! Only drawback: we need $s\ll \ab$ for our approximations to be valid (after that, $\expect{\p(S)}$ cannot be approximately $s\normtwo{\p}^2$ anymore; same issue as with the ``unique elements'' algorithm), so we get the condition $\dst \gg 1/\ab^{1/4}$. Slight bummer.
%%%%%%%%%% Bibliography
\begin{filecontents}{references-uniformity.bib}

@article{GoldreichR00,
  author    = {Oded Goldreich and
               Dana Ron},
  title     = {On Testing Expansion in Bounded-Degree Graphs},
  journal   = {Electronic Colloquium on Computational Complexity {(ECCC)}},
  volume    = {7},
  number    = {20},
  year      = {2000}
}

@article{DiakonikolasGPP19,
    AUTHOR = {Diakonikolas, Ilias and Gouleakis, Themis and Peebles, John
              and Price, Eric},
     TITLE = {Collision-based testers are optimal for uniformity and
              closeness},
   JOURNAL = {Chic. J. Theoret. Comput. Sci.},
  FJOURNAL = {Chicago Journal of Theoretical Computer Science},
      YEAR = {2019},
     PAGES = {Art. 1, 21},
   MRCLASS = {62F03 (62F99)},
  MRNUMBER = {4008852},
       DOI = {10.4086/cjtcs.2019.001},
       URL = {https://doi.org/10.4086/cjtcs.2019.001},
}

@article{AcharyaDK15,
  author    = {Jayadev Acharya and
               Constantinos Daskalakis and
               Gautam Kamath},
  title     = {Optimal Testing for Properties of Distributions},
  journal   = {CoRR},
  volume    = {abs/1507.05952},
  year      = {2015}
}

@inproceedings{DiakonikolasKN15,
  author    = {Ilias Diakonikolas and
               Daniel M. Kane and
               Vladimir Nikishkin},
  title     = {Testing Identity of Structured Distributions},
  booktitle = {{SODA}},
  pages     = {1841--1854},
  publisher = {{SIAM}},
  year      = {2015}
}

@inproceedings{DiakonikolasGKR19,
  author    = {Ilias Diakonikolas and
               Themis Gouleakis and
               Daniel M. Kane and
               Sankeerth Rao},
  title     = {Communication and Memory Efficient Testing of Discrete Distributions},
  booktitle = {{COLT}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {99},
  pages     = {1070--1106},
  publisher = {{PMLR}},
  year      = {2019}
}

@article{ValiantV17,
    AUTHOR = {Valiant, Gregory and Valiant, Paul},
     TITLE = {An automatic inequality prover and instance optimal identity
              testing},
   JOURNAL = {SIAM J. Comput.},
  FJOURNAL = {SIAM Journal on Computing},
    VOLUME = {46},
      YEAR = {2017},
    NUMBER = {1},
     PAGES = {429--455},
      ISSN = {0097-5397},
   MRCLASS = {68Q30 (26D15 62G10 68Q25 68T15)},
  MRNUMBER = {3614697},
MRREVIEWER = {Gilles Teyssi\`ere},
       DOI = {10.1137/151002526},
       URL = {https://doi.org/10.1137/151002526},
      NOTE = {Journal version of~\cite{ValiantValiant14}.}
}

@incollection{ValiantValiant14,
    AUTHOR = {Valiant, Gregory and Valiant, Paul},
     TITLE = {An automatic inequality prover and instance optimal identity
              testing},
 BOOKTITLE = {55th {A}nnual {IEEE} {S}ymposium on {F}oundations of
              {C}omputer {S}cience---{FOCS} 2014},
     PAGES = {51--60},
 PUBLISHER = {IEEE Computer Soc., Los Alamitos, CA},
      YEAR = {2014},
   MRCLASS = {62E15 (94A15)},
  MRNUMBER = {3344854},
       DOI = {10.1109/FOCS.2014.14},
       URL = {https://doi.org/10.1109/FOCS.2014.14},
}

@article{Paninski08,
    AUTHOR = {Paninski, Liam},
     TITLE = {A coincidence-based test for uniformity given very sparsely
              sampled discrete data},
   JOURNAL = {IEEE Trans. Inform. Theory},
  FJOURNAL = {Institute of Electrical and Electronics Engineers.
              Transactions on Information Theory},
    VOLUME = {54},
      YEAR = {2008},
    NUMBER = {10},
     PAGES = {4750--4755},
      ISSN = {0018-9448},
   MRCLASS = {62F03 (94A12)},
  MRNUMBER = {2591136},
       DOI = {10.1109/TIT.2008.928987},
       URL = {https://doi.org/10.1109/TIT.2008.928987},
}

@inproceedings{DiakonikolasGPP18,
    AUTHOR = {Diakonikolas, Ilias and Gouleakis, Themis and Peebles, John
              and Price, Eric},
     TITLE = {Sample-optimal identity testing with high probability},
 BOOKTITLE = {45th {I}nternational {C}olloquium on {A}utomata, {L}anguages,
              and {P}rogramming},
    SERIES = {LIPIcs. Leibniz Int. Proc. Inform.},
    VOLUME = {107},
     PAGES = {Art. No. 41, 14},
 PUBLISHER = {Schloss Dagstuhl. Leibniz-Zent. Inform., Wadern},
      YEAR = {2018},
   MRCLASS = {68W20},
  MRNUMBER = {3829972},
}

@inproceedings{AcharyaCT19,
  author    = {Jayadev Acharya and
               Cl{\'{e}}ment L. Canonne and
               Himanshu Tyagi},
  title     = {Inference under Information Constraints: Lower Bounds from Chi-Square
               Contraction},
  booktitle = {{COLT}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {99},
  pages     = {3--17},
  publisher = {{PMLR}},
  year      = {2019}
}


@inproceedings{AcharyaCFT19,
  author    = {Jayadev Acharya and
               Cl{\'{e}}ment L. Canonne and
               Cody Freitag and
               Himanshu Tyagi},
  title     = {Test without Trust: Optimal Locally Private Distribution Testing},
  booktitle = {{AISTATS}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  pages     = {2067--2076},
  publisher = {{PMLR}},
  year      = {2019}
}

@article{KareemMJ19,
  author    = {Kareem Amin and
               Matthew Joseph and
               Jieming Mao},
  title     = {Pan-Private Uniformity Testing},
  journal   = {CoRR},
  volume    = {abs/1911.01452},
  year      = {2019}
}

@article{BalcerCJM20,
  author    = {Victor Balcer and
               Albert Cheu and
               Matthew Joseph and
               Jieming Mao},
  title     = {Connecting Robust Shuffle Privacy and Pan-Privacy},
  journal   = {CoRR},
  volume    = {abs/2004.09481},
  year      = {2020}
}

@incollection{Goldreich16,
  author    = {Oded Goldreich},
  title     = {The Uniform Distribution Is Complete with Respect to Testing Identity
               to a Fixed Distribution},
  booktitle = {Computational Complexity and Property Testing},
  series    = {Lecture Notes in Computer Science},
  volume    = {12050},
  pages     = {152--172},
  publisher = {Springer},
  year      = {2020}
}
@article{BalakrishnanW18,
    AUTHOR = {Balakrishnan, Sivaraman and Wasserman, Larry},
     TITLE = {Hypothesis testing for high-dimensional multinomials: a
              selective review},
   JOURNAL = {Ann. Appl. Stat.},
  FJOURNAL = {The Annals of Applied Statistics},
    VOLUME = {12},
      YEAR = {2018},
    NUMBER = {2},
     PAGES = {727--749},
      ISSN = {1932-6157},
   MRCLASS = {62H15 (62-02)},
  MRNUMBER = {3834283},
       DOI = {10.1214/18-AOAS1155SF},
       URL = {https://doi.org/10.1214/18-AOAS1155SF},
}

@incollection{DiakonikolasK16,
    AUTHOR = {Diakonikolas, Ilias and Kane, Daniel M.},
     TITLE = {A new approach for testing properties of discrete
              distributions},
 BOOKTITLE = {57th {A}nnual {IEEE} {S}ymposium on {F}oundations of
              {C}omputer {S}cience---{FOCS} 2016},
     PAGES = {685--694},
 PUBLISHER = {IEEE Computer Soc., Los Alamitos, CA},
      YEAR = {2016},
   MRCLASS = {68W20 (68Q87)},
  MRNUMBER = {3631031},
}

@InProceedings{AcharyaCT19b,
  title = 	 {Communication-Constrained Inference and the Role of Shared Randomness},
  author = 	 {Acharya, Jayadev and Canonne, Clement and Tyagi, Himanshu},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {30--39},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/acharya19a/acharya19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/acharya19a.html}
}

@article{AcharyaCHST19,
  author    = {Jayadev Acharya and
               Cl{\'{e}}ment L. Canonne and
               Yanjun Han and
               Ziteng Sun and
               Himanshu Tyagi},
  title     = {Domain Compression and its Application to Randomness-Optimal Distributed
               Goodness-of-Fit},
  journal   = {CoRR},
  volume    = {abs/1907.08743},
  year      = {2019}
}

% Privacy models
@inproceedings{DworkMNS06,
  author        = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  title         = {Calibrating Noise to Sensitivity in Private Data Analysis},
  booktitle     = {Proceedings of the 3rd Conference on Theory of Cryptography},
  series        = {TCC '06},
  year          = {2006},
  pages         = {265--284},
  publisher     = {Springer},
  address       = {Berlin, Heidelberg}
}


@article{KasiviswanathanLNRS11,
    AUTHOR = {Kasiviswanathan, Shiva Prasad and Lee, Homin K. and Nissim,
              Kobbi and Raskhodnikova, Sofya and Smith, Adam},
     TITLE = {What can we learn privately?},
   JOURNAL = {SIAM J. Comput.},
  FJOURNAL = {SIAM Journal on Computing},
    VOLUME = {40},
      YEAR = {2011},
    NUMBER = {3},
     PAGES = {793--826},
      ISSN = {0097-5397},
   MRCLASS = {68Q32},
  MRNUMBER = {2823508},
MRREVIEWER = {Martin Anthony},
       DOI = {10.1137/090756090},
       URL = {https://doi.org/10.1137/090756090},
      NOTE = {Journal version of~\cite{KasiviswanathanLNRS08}.}
}

@inproceedings{KasiviswanathanLNRS08,
  author    = {Shiva Prasad Kasiviswanathan and
               Homin K. Lee and
               Kobbi Nissim and
               Sofya Raskhodnikova and
               Adam D. Smith},
  title     = {What Can We Learn Privately?},
  booktitle = {49th Annual IEEE Symposium on Foundations of Computer Science---{FOCS} 2008}, 
  pages     = {531--540},
  publisher = {{IEEE} Computer Society},
  year      = {2008}
}

@inproceedings{DuchiJW13,
  author    = {John C. Duchi and
               Michael I. Jordan and
               Martin J. Wainwright},
  title     = {Local Privacy and Statistical Minimax Rates},
  booktitle = {54th Annual IEEE Symposium on Foundations of Computer Science---{FOCS} 2013}, 
  pages     = {429--438},
  publisher = {{IEEE} Computer Society},
  year      = {2013}
}

@inproceedings{DworkNPRY10,
  author    = {Cynthia Dwork and
               Moni Naor and
               Toniann Pitassi and
               Guy N. Rothblum and
               Sergey Yekhanin},
  title     = {Pan-Private Streaming Algorithms},
  booktitle = {{ICS}},
  pages     = {66--80},
  publisher = {Tsinghua University Press},
  year      = {2010}
}

@misc{Cheu2020,
     title = {{The Sudden Surge of Shuffling in the Privacy Literature}},
    author = {Cheu, Albert},
    url    = {http://ccis.northeastern.edu/home/albertcheu/shuffledmodel.html},
    note   = {Online; accessed 24 April 2020}, 
    year   = {2020}
}

@incollection{CheuSUZZ19,
    AUTHOR = {Cheu, Albert and Smith, Adam and Ullman, Jonathan and Zeber,
              David and Zhilyaev, Maxim},
     TITLE = {Distributed differential privacy via shuffling},
 BOOKTITLE = {Advances in cryptology---{EUROCRYPT} 2019. {P}art {I}},
    SERIES = {Lecture Notes in Comput. Sci.},
    VOLUME = {11476},
     PAGES = {375--403},
 PUBLISHER = {Springer, Cham},
      YEAR = {2019},
   MRCLASS = {94A62},
  MRNUMBER = {3964546},
       DOI = {10.1007/978-3-030-17653-2_13},
       URL = {https://doi.org/10.1007/978-3-030-17653-2_13},
}

@article {HuangM13,
    AUTHOR = {Huang, Dayu and Meyn, Sean},
     TITLE = {Generalized error exponents for small sample universal
              hypothesis testing},
   JOURNAL = {IEEE Trans. Inform. Theory},
  FJOURNAL = {Institute of Electrical and Electronics Engineers.
              Transactions on Information Theory},
    VOLUME = {59},
      YEAR = {2013},
    NUMBER = {12},
     PAGES = {8157--8181},
      ISSN = {0018-9448},
   MRCLASS = {62G10 (60F10 62G20)},
  MRNUMBER = {3142287},
MRREVIEWER = {Yoshihiko Maesono},
       DOI = {10.1109/TIT.2013.2283266},
       URL = {https://doi.org/10.1109/TIT.2013.2283266},
}

% To update once published in ToC
@article{Canonne15,
  author    = {Cl{\'{e}}ment L. Canonne},
  title     = {A Survey on Distribution Testing: Your Data is Big. But is it Blue?},
  journal   = {Electronic Colloquium on Computational Complexity {(ECCC)}},
  volume    = {22},
  pages     = {63},
  year      = {2015},
  url       = {http://eccc.hpi-web.de/report/2015/063},
  timestamp = {Tue, 14 Aug 2018 17:08:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/eccc/Canonne15},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  note = {To appear as a graduate student survey in Theory of Computing}
}
\end{filecontents}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{alpha}
\bibliography{references-uniformity}
\end{document}
